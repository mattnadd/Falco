{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMZEiImFvbCy"
   },
   "source": [
    "# Sentiment Classification Using DistilBERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EE0wCLsGvhnM"
   },
   "source": [
    "We will use IMDB Movie Reviews Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2ZRiGpERSK1"
   },
   "source": [
    "# What is `DistilBERT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-yzge4wUw08Q"
   },
   "source": [
    "BERT is designed to pretrain deep bidirectional representations from\n",
    "unlabeled text by jointly conditioning on both\n",
    "left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer\n",
    "to create state-of-the-art models for a wide\n",
    "range of tasks, such as question answering and\n",
    "language inference, without substantial taskspecific architecture modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMEy6Ptaw1Ab"
   },
   "source": [
    "DistilBERT is a small, fast, cheap and light Transformer model trained by distilling Bert base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of Bertâ€™s performances as measured on the GLUE language understanding benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6X4HjQXtRY2c"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/2000/1*IFVX74cEe8U5D1GveL1uZA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4uCVI3wRYyx"
   },
   "source": [
    "## Why `DistilBERT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bd5fc8HMRYtB"
   },
   "source": [
    "\n",
    "\n",
    "*   Accurate as much as Original BERT Model\n",
    "*   60% faster \n",
    "*   40% less parameters\n",
    "*   It can run on CPU\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_X4-4St4PN3Y"
   },
   "source": [
    "### Additional Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86WtEhL7os98"
   },
   "source": [
    "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\n",
    "\n",
    "https://arxiv.org/abs/1910.01108"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6qkeIkR4w99"
   },
   "source": [
    "Video Lecture: BERT NLP Tutorial 1- Introduction | BERT Machine Learning | KGP Talkie\n",
    "\n",
    "https://www.youtube.com/watch?v=h_U27jBNYI4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CduweRwoRY6e"
   },
   "source": [
    "Ref BERT:  **Pre-training of Deep Bidirectional Transformers for\n",
    "Language Understanding**\n",
    "\n",
    "https://arxiv.org/abs/1810.04805"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_Od_6p6vj43"
   },
   "source": [
    "Understanding searches better than ever before:\n",
    "\n",
    "https://www.blog.google/products/search/search-language-understanding-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHcY9C3HvkFv"
   },
   "source": [
    "Good Resource to Read More About the BERT: \n",
    "\n",
    "http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gk4fT8-_vjzI"
   },
   "source": [
    "Visual Guide to Using BERT:\n",
    " \n",
    "http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-BlBvZSTvqU"
   },
   "source": [
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lL9_qWcSRYnZ"
   },
   "source": [
    "# What is `ktrain`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-KPOCk1RYj2"
   },
   "source": [
    "ktrain is a library to help build, train, debug, and deploy neural networks in the deep learning software framework, Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSDYTd2jz_9x"
   },
   "source": [
    "ktrain uses tf.keras in TensorFlow instead of standalone Keras.) Inspired by the fastai library, with only a few lines of code, ktrain allows you to easily:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ef5yYyUZz_4l"
   },
   "source": [
    "*   estimate an optimal learning rate for your model given your data using a learning rate finder\n",
    "*   employ learning rate schedules such as the triangular learning rate policy, 1cycle policy, and SGDR to more effectively train your model\n",
    "*   employ fast and easy-to-use pre-canned models for both text classification (e.g., NBSVM, fastText, GRU with pretrained word embeddings) and image classification (e.g., ResNet, Wide Residual Networks, Inception)\n",
    "*   load and preprocess text and image data from a variety of formats\n",
    "\n",
    "*   inspect data points that were misclassified to help improve your model\n",
    "*   leverage a simple prediction API for saving and deploying both models and data-preprocessing steps to make predictions on new raw data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVzZNy0_z_0o"
   },
   "source": [
    "ktrain GitHub: https://github.com/amaiya/ktrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThRISEExRYgb"
   },
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yhnjIqyT4adZ",
    "outputId": "b2577f3a-7621-4a03-e481-d2e048cdca28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ktrain in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (0.30.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (1.0.1)\n",
      "Requirement already satisfied: cchardet in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (2.1.7)\n",
      "Requirement already satisfied: requests in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (2.25.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (1.2.4)\n",
      "Requirement already satisfied: transformers==4.10.3 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (4.10.3)\n",
      "Requirement already satisfied: langdetect in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (1.0.9)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (3.3.4)\n",
      "Requirement already satisfied: chardet in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (4.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (20.9)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (0.1.95)\n",
      "Requirement already satisfied: whoosh in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (2.7.4)\n",
      "Requirement already satisfied: keras-bert>=0.86.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (0.89.0)\n",
      "Requirement already satisfied: jieba in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (0.42.1)\n",
      "Requirement already satisfied: syntok==1.3.3 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (1.3.3)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: scikit-learn==0.24.2 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from ktrain) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2->ktrain) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2->ktrain) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2->ktrain) (1.19.5)\n",
      "Requirement already satisfied: regex in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from syntok==1.3.3->ktrain) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (0.0.45)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (5.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (0.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (4.59.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers==4.10.3->ktrain) (3.7.4.3)\n",
      "Requirement already satisfied: keras-transformer==0.40.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
      "Requirement already satisfied: keras-pos-embd==0.13.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
      "Requirement already satisfied: keras-multi-head==0.29.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
      "Requirement already satisfied: keras-layer-normalization==0.16.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
      "Requirement already satisfied: keras-embed-sim==0.10.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: keras-self-attention==0.51.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->ktrain) (2021.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from requests->ktrain) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from requests->ktrain) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\mnadd\\anaconda3\\lib\\site-packages (from sacremoses->transformers==4.10.3->ktrain) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mnadd\\\\Falco'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "V8lwTCvX4abU",
    "outputId": "23d71678-f5be-4cbf-b4c5-3059e22c6127"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'IMDB-Movie-Reviews-Large-Dataset-50k' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/laxmimerit/IMDB-Movie-Reviews-Large-Dataset-50k.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GepWKkM4aVF"
   },
   "outputs": [],
   "source": [
    "# /content/IMDB-Movie-Reviews-Large-Dataset-50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YW_Jxjqf4aSJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYCOq0GB0edr"
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_excel('C:\\\\Users\\\\mnadd\\\\Falco\\\\IMDB-Movie-Reviews-Large-Dataset-50k\\\\test.xlsx', dtype= str)\n",
    "data_train = pd.read_excel('C:\\\\Users\\\\mnadd\\\\Falco\\\\IMDB-Movie-Reviews-Large-Dataset-50k\\\\train.xlsx', dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mnadd\\\\Falco'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "VPffRgyM1Vc9",
    "outputId": "de57bfe8-7405-4a89-c7d3-d0639c46511d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>Tierney's an authentic tough guy, but this mov...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21523</th>\n",
       "      <td>I created my own reality by walking out of the...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>I have seen about a thousand horror films. (my...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22919</th>\n",
       "      <td>Wow! Only a movie this ludicrously awful could...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>i thought this movie was wonderfully plotted i...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Reviews Sentiment\n",
       "6503   Tierney's an authentic tough guy, but this mov...       neg\n",
       "21523  I created my own reality by walking out of the...       neg\n",
       "1202   I have seen about a thousand horror films. (my...       neg\n",
       "22919  Wow! Only a movie this ludicrously awful could...       neg\n",
       "7634   i thought this movie was wonderfully plotted i...       pos"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "QnXGDGYE1Yn5",
    "outputId": "ee43d994-4976-49e9-e61b-b34f6efe9a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext: a fastText-like model [http://arxiv.org/pdf/1607.01759.pdf]\n",
      "logreg: logistic regression using a trainable Embedding layer\n",
      "nbsvm: NBSVM model [http://www.aclweb.org/anthology/P12-2018]\n",
      "bigru: Bidirectional GRU with pretrained fasttext word vectors [https://fasttext.cc/docs/en/crawl-vectors.html]\n",
      "standard_gru: simple 2-layer GRU with randomly initialized embeddings\n",
      "bert: Bidirectional Encoder Representations from Transformers (BERT) from keras_bert [https://arxiv.org/abs/1810.04805]\n",
      "distilbert: distilled, smaller, and faster BERT from Hugging Face transformers [https://arxiv.org/abs/1910.01108]\n"
     ]
    }
   ],
   "source": [
    "text.print_text_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "ArjDvkJn1pwp",
    "outputId": "8c87b766-6e04-4ff4-ef7d-8989da1451fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n",
      "   neg  pos\n",
      "0  1.0  0.0\n",
      "1  1.0  0.0\n",
      "2  1.0  0.0\n",
      "3  1.0  0.0\n",
      "4  1.0  0.0\n",
      "['neg', 'pos']\n",
      "   neg  pos\n",
      "0  0.0  1.0\n",
      "1  0.0  1.0\n",
      "2  1.0  0.0\n",
      "3  0.0  1.0\n",
      "4  1.0  0.0\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 234\n",
      "\t95percentile : 598\n",
      "\t99percentile : 913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 234\n",
      "\t95percentile : 598\n",
      "\t99percentile : 913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train, val, preproc) = text.texts_from_df(train_df=data_train, text_column='Reviews', label_columns='Sentiment',\n",
    "                   val_df = data_test,\n",
    "                   maxlen = 400,\n",
    "                   preprocess_mode = 'distilbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "mnwYNxJb2XIm",
    "outputId": "206512a7-5081-4f4f-bcc6-cb0cd92d040e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 400\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier(name = 'distilbert', train_data = train, preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26QFg7VV4nvG"
   },
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model = model,\n",
    "                             train_data = train,\n",
    "                             val_data = val,\n",
    "                             batch_size = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "aNcVJ__v4nqE",
    "outputId": "1ec845b3-838e-42b9-d3c4-42c624b3295b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/2\n",
      "4167/4167 [==============================] - 16046s 4s/step - loss: 0.2923 - accuracy: 0.8777 - val_loss: 0.1630 - val_accuracy: 0.9389\n",
      "Epoch 2/2\n",
      "4167/4167 [==============================] - 16017s 4s/step - loss: 0.1576 - accuracy: 0.9408 - val_loss: 0.0652 - val_accuracy: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23079752be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(lr = 2e-5, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rW8bsakl4nl6"
   },
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NLK_GuB4nim"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "qSfKspeDVfI8",
    "outputId": "4c897140-bd5f-4162-e02c-5d43dcffb744"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xI0NpQN4nf4"
   },
   "outputs": [],
   "source": [
    "predictor.save('/content/drive/My Drive/distilbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnqXw9CA4ndM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBN4Jk8u4naa"
   },
   "outputs": [],
   "source": [
    "data = ['this movie was really bad. acting was also bad. I will not watch again',\n",
    "        'the movie was really great. I will see it again', 'another great movie. must watch to everyone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xkJWZAXk4nXM",
    "outputId": "13748802-de9c-4ba7-f04e-327ec256af75"
   },
   "outputs": [],
   "source": [
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9oiO-7qy26Zp",
    "outputId": "494fd588-f0e9-4481-ca7c-f81d6996a4b7"
   },
   "outputs": [],
   "source": [
    "predictor.get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Gl8bGAUoW-A7",
    "outputId": "1370b791-c2c4-4fb8-e58d-cc25d92ca73b"
   },
   "outputs": [],
   "source": [
    "predictor.predict(data, return_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34y6Ud0QXL0i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment_Classification_using_DistilBERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
